{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8c362",
   "metadata": {
    "id": "c4c8c362"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, concatenate, Dropout, Conv2D, GlobalAveragePooling2D,Conv2DTranspose, MaxPooling2D, UpSampling2D, Input, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import filterwarnings\n",
    "from tensorflow.keras.models import load_model\n",
    "import itertools\n",
    "filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d17f",
   "metadata": {
    "id": "85d0d17f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "# policy = mixed_precision.Policy('float32')\n",
    "# mixed_precision.set_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b119b02",
   "metadata": {
    "id": "5b119b02"
   },
   "outputs": [],
   "source": [
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "val_dir= \"val\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d17e6",
   "metadata": {
    "id": "448d17e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (224, 224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287f8f3",
   "metadata": {
    "id": "c287f8f3",
    "outputId": "16e0e0c3-d31e-469b-891f-2b5f4196d2b2"
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False)\n",
    "\n",
    "\n",
    "\n",
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "datagen_val=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 20\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "generator_val = datagen_val.flow_from_directory(directory=val_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                class_mode='categorical',\n",
    "                                                  shuffle=False)\n",
    "generator_test=datagen_test.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                class_mode='categorical',\n",
    "                                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b740726",
   "metadata": {
    "id": "7b740726"
   },
   "source": [
    "def print_layer_trainable():\n",
    "    for layer in model1.layers:\n",
    "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n",
    "\n",
    "\n",
    "# print_layer_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea8c2b",
   "metadata": {
    "id": "88ea8c2b",
    "outputId": "2f09d37f-f6c0-47b1-fbe1-b1fc6faad37a"
   },
   "outputs": [],
   "source": [
    "classes=list(generator_train.class_indices.keys())\n",
    "class_count=len(classes)\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c20327",
   "metadata": {
    "id": "f8c20327"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0039cd",
   "metadata": {
    "id": "cb0039cd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    channels = input_tensor.shape[-1]\n",
    "\n",
    "    # Squeeze operation\n",
    "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
    "\n",
    "    # Excite operation\n",
    "    excite = layers.Dense(channels // ratio, activation='relu')(squeeze)\n",
    "    excite = layers.Dense(channels, activation='sigmoid')(excite)\n",
    "\n",
    "    # Reshape to (batch_size, 1, 1, channels)\n",
    "    excite = tf.keras.layers.Reshape((1, 1, channels))(excite)\n",
    "\n",
    "    # Scale the input with the excitation weights\n",
    "    scaled_input = layers.Multiply()([input_tensor, excite])\n",
    "\n",
    "    return scaled_input\n",
    "\n",
    "# Define a more complex and parameter-efficient CNN model\n",
    "input_shape = (224, 224, 3)\n",
    "input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation='relu', padding='same')(input_tensor)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = squeeze_excite_block(x)\n",
    "\n",
    "# Depthwise separable convolutional layers\n",
    "x = layers.SeparableConv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.SeparableConv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.SeparableConv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.SeparableConv2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = squeeze_excite_block(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Global average pooling\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu',dtype='float32')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Output layer\n",
    "output_tensor = layers.Dense(4, activation='softmax')(x)  #\n",
    "\n",
    "# Create the model\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if your labels are integers\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a19a41",
   "metadata": {
    "id": "79a19a41",
    "outputId": "67f3db6e-288d-4e4d-e908-0be599554512",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 56, 56, 128)  0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0          ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 28, 28, 256)  34176      ['max_pooling2d_2[0][0]']        \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 28, 256)  1024       ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 256)         0           ['batch_normalization_4[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           4112        ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          4352        ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 256)    0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 28, 28, 256)  0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 256)  0          ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 256)         0           ['max_pooling2d_3[0][0]']        \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          65792       ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 256)         1024        ['dense_10[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          32896       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128)         512         ['dense_11[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 4)            516         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,778\n",
      "Trainable params: 178,794\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=1e-4)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy','Precision','Recall']\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7caa2d",
   "metadata": {
    "id": "3e7caa2d",
    "outputId": "1bae119b-f8a9-4d77-95e2-254a382add67"
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(layer.name, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0fb32",
   "metadata": {
    "id": "e0f0fb32",
    "outputId": "3057f400-8031-44ff-9fa2-fd9a9a4b482e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 56, 56, 128)  0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 128)  0          ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 28, 28, 256)  34176      ['max_pooling2d_2[0][0]']        \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,550\n",
      "Trainable params: 69,846\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_layer_removed = tf.keras.models.Model(inputs=model.input, outputs=model.layers[32].output)\n",
    "model_layer_removed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93708474",
   "metadata": {
    "id": "93708474",
    "outputId": "3abc8ee8-fc20-4ecb-9069-039d96fce259"
   },
   "outputs": [],
   "source": [
    "x, y = generator_train.__next__()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd521f",
   "metadata": {
    "id": "3cfd521f",
    "outputId": "474caa4f-ca48-4cc3-c217-96e223e7d583"
   },
   "outputs": [],
   "source": [
    "predict_layers_removed = model_layer_removed.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eccbd",
   "metadata": {
    "id": "a48eccbd",
    "outputId": "882683b8-5b64-441a-8769-edee1e66f1f1"
   },
   "outputs": [],
   "source": [
    "predict_layers_removed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068db7ac",
   "metadata": {
    "id": "068db7ac",
    "outputId": "f9b252e3-236a-4455-d92a-c8178f595eb8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(128):\n",
    "    plt.imshow(predict_layers_removed[0, :, :, i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9c2c8",
   "metadata": {
    "id": "9bb9c2c8",
    "outputId": "3d94b1f4-a001-4c68-bcd3-b7a1d8f38789"
   },
   "outputs": [],
   "source": [
    "c,r=8,8\n",
    "for i in predict_layers_removed :\n",
    "    fig=plt.figure(figsize=(12,12))\n",
    "    for j in range(1,c*r+1):\n",
    "        fig=plt.subplot(r,c,j)\n",
    "        fig.set_xticks([])\n",
    "        fig.set_yticks([])\n",
    "        plt.imshow(predict_layers_removed[0, :, :, j-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2df68c",
   "metadata": {
    "id": "ed2df68c",
    "outputId": "b3035b43-936d-4a0b-8650-4074d0cff85d"
   },
   "outputs": [],
   "source": [
    "model_layer_removed = tf.keras.models.Model(inputs=model.input, outputs=model.layers[24].output)\n",
    "x, y = generator_train.__next__()\n",
    "predict_layers_removed = model_layer_removed.predict(x)\n",
    "c,r=8,8\n",
    "for i in predict_layers_removed :\n",
    "    fig=plt.figure(figsize=(12,12))\n",
    "    for j in range(1,c*r+1):\n",
    "        fig=plt.subplot(r,c,j)\n",
    "        fig.set_xticks([])\n",
    "        fig.set_yticks([])\n",
    "        plt.imshow(predict_layers_removed[0, :, :, j-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15dd6c",
   "metadata": {
    "id": "7f15dd6c",
    "outputId": "3db56ac2-0299-46dc-ff22-f9b093d4d599"
   },
   "outputs": [],
   "source": [
    "model_layer_removed = tf.keras.models.Model(inputs=model.input, outputs=model.layers[8].output)\n",
    "x, y = generator_train.__next__()\n",
    "predict_layers_removed = model_layer_removed.predict(x)\n",
    "c,r=8,8\n",
    "for i in predict_layers_removed :\n",
    "    fig=plt.figure(figsize=(12,12))\n",
    "    for j in range(1,c*r+1):\n",
    "        fig=plt.subplot(r,c,j)\n",
    "        fig.set_xticks([])\n",
    "        fig.set_yticks([])\n",
    "        plt.imshow(predict_layers_removed[0, :, :, j-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78cf9b",
   "metadata": {
    "id": "1a78cf9b",
    "outputId": "def9462a-7460-40c1-a222-f6df1017d0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0548 - accuracy: 0.9818 - precision: 0.9821 - recall: 0.9806 - val_loss: 0.4170 - val_accuracy: 0.8875 - val_precision: 0.8870 - val_recall: 0.8826\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 22s 134ms/step - loss: 0.0514 - accuracy: 0.9803 - precision: 0.9821 - recall: 0.9788 - val_loss: 0.2807 - val_accuracy: 0.8973 - val_precision: 0.9129 - val_recall: 0.8973\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0503 - accuracy: 0.9815 - precision: 0.9827 - recall: 0.9809 - val_loss: 0.0162 - val_accuracy: 0.9976 - val_precision: 0.9976 - val_recall: 0.9976\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0421 - accuracy: 0.9880 - precision: 0.9883 - recall: 0.9868 - val_loss: 0.0416 - val_accuracy: 0.9780 - val_precision: 0.9780 - val_recall: 0.9780\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 22s 135ms/step - loss: 0.0329 - accuracy: 0.9883 - precision: 0.9886 - recall: 0.9877 - val_loss: 0.0176 - val_accuracy: 0.9951 - val_precision: 0.9951 - val_recall: 0.9951\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 22s 134ms/step - loss: 0.0425 - accuracy: 0.9852 - precision: 0.9864 - recall: 0.9849 - val_loss: 0.0445 - val_accuracy: 0.9902 - val_precision: 0.9902 - val_recall: 0.9902\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0359 - accuracy: 0.9883 - precision: 0.9889 - recall: 0.9880 - val_loss: 0.4722 - val_accuracy: 0.8533 - val_precision: 0.8610 - val_recall: 0.8484\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 22s 134ms/step - loss: 0.0498 - accuracy: 0.9825 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.1816 - val_accuracy: 0.9438 - val_precision: 0.9459 - val_recall: 0.9413\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0467 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9837 - val_loss: 0.0504 - val_accuracy: 0.9804 - val_precision: 0.9804 - val_recall: 0.9804\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 22s 134ms/step - loss: 0.0409 - accuracy: 0.9877 - precision: 0.9877 - recall: 0.9871 - val_loss: 0.3307 - val_accuracy: 0.8802 - val_precision: 0.8859 - val_recall: 0.8729\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0543 - accuracy: 0.9828 - precision: 0.9830 - recall: 0.9818 - val_loss: 0.4677 - val_accuracy: 0.8973 - val_precision: 0.9030 - val_recall: 0.8875\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0349 - accuracy: 0.9886 - precision: 0.9889 - recall: 0.9883 - val_loss: 0.1220 - val_accuracy: 0.9584 - val_precision: 0.9608 - val_recall: 0.9584\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: 0.0398 - accuracy: 0.9861 - precision: 0.9868 - recall: 0.9861 - val_loss: 0.0227 - val_accuracy: 0.9927 - val_precision: 0.9927 - val_recall: 0.9927\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 22s 134ms/step - loss: 0.0380 - accuracy: 0.9861 - precision: 0.9874 - recall: 0.9855 - val_loss: 0.0140 - val_accuracy: 0.9951 - val_precision: 0.9951 - val_recall: 0.9951\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs =50\n",
    "steps_per_epoch = generator_train.n / batch_size\n",
    "steps_test = generator_test.n / batch_size\n",
    "\n",
    "#steps_per_epoch = 20\n",
    "# steps_test = 50\n",
    "early_stop = EarlyStopping(patience=5)\n",
    "history = model.fit_generator(generator=generator_train,\n",
    "                              epochs=epochs,\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              validation_data=generator_val,\n",
    "                              validation_steps=steps_test,\n",
    "\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40e8a5",
   "metadata": {
    "id": "2c40e8a5"
   },
   "outputs": [],
   "source": [
    "model.save(\"GLNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08096f32",
   "metadata": {
    "id": "08096f32",
    "outputId": "6524449d-7d51-4182-e10c-2766323167f6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Plot the model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe43dcb",
   "metadata": {
    "id": "6fe43dcb",
    "outputId": "98b651c8-5680-42f3-d1db-c7fdd483f38a"
   },
   "outputs": [],
   "source": [
    "#Get the accuracy score\n",
    "\n",
    "test_score = model.evaluate_generator(generator_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100))\n",
    "\n",
    "print(\"[INFO] Loss: {:.2f}%\".format(test_score[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb0506",
   "metadata": {
    "id": "3cbb0506",
    "outputId": "7ba39a10-8d4d-42aa-dba3-5ccce2b4d4bd"
   },
   "outputs": [],
   "source": [
    "#Get the accuracy score\n",
    "\n",
    "test_score = model.evaluate_generator(generator_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(test_score[1] * 100))\n",
    "\n",
    "print(\"[INFO] Loss: {:.2f}%\".format(test_score[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8ccb3",
   "metadata": {
    "id": "90b8ccb3",
    "outputId": "976f187e-0d8a-4a8a-ca40-0673bc00d80e"
   },
   "outputs": [],
   "source": [
    "classes=list(generator_train.class_indices.keys())\n",
    "class_count=len(classes)\n",
    "print(class_count)\n",
    "li=[1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b197f2",
   "metadata": {
    "id": "83b197f2",
    "outputId": "304f62bf-6649-4a40-b108-c683d01191d7"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y_pred = model.predict_generator(generator_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "array = confusion_matrix(generator_test.classes, y_pred)\n",
    "df_cm = pd.DataFrame(array, index =li,\n",
    "                  columns = li)\n",
    "plt.figure(figsize=(10,10))\n",
    "sn.set(font_scale=2.0)\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion matrix of GLNet')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('CNN_confusion',dpi=200);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76755806",
   "metadata": {
    "id": "76755806",
    "outputId": "853edfac-88ce-4348-e495-6ea0f86f5c86"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(generator_test.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf473ea5",
   "metadata": {
    "id": "bf473ea5",
    "outputId": "2f2cd4b1-166b-48e2-817c-d6023f85864d"
   },
   "outputs": [],
   "source": [
    "target_names = []\n",
    "\n",
    "for key in generator_train.class_indices:\n",
    "\n",
    "    target_names.append(key)\n",
    "\n",
    "\n",
    "\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77188e9e",
   "metadata": {
    "id": "77188e9e",
    "outputId": "3a06c410-f7a3-4a58-9393-49e79a59a7e1"
   },
   "outputs": [],
   "source": [
    "preds = model.predict_generator(generator_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a9fda",
   "metadata": {
    "id": "365a9fda",
    "outputId": "87ce9601-c345-466c-94e6-afe158aa4203"
   },
   "outputs": [],
   "source": [
    "print(classification_report(generator_test.classes, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59624a5",
   "metadata": {
    "id": "b59624a5",
    "outputId": "b1bdbe7f-fd40-43d3-b72d-30c3faf753b4"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].grid(color = '#e0e0eb')\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c59527",
   "metadata": {
    "id": "57c59527",
    "outputId": "7bd8b05b-12bb-48db-a962-fe389fa5ff33"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "ax = ax.ravel()\n",
    "for i, met in enumerate([ 'accuracy', 'loss']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('GLNet Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].grid(color = '#e0e0eb')\n",
    "    ax[i].legend(['train', 'val'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888fc54",
   "metadata": {
    "id": "c888fc54",
    "outputId": "812fa494-1292-40dc-f4ed-e766d7d21837"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"#eaeaf2\")\n",
    "plt.plot(history.history['accuracy'],label=\"train accuracy\")\n",
    "plt.plot(history.history['val_accuracy'],label=\"val accuracy\")\n",
    "plt.title('GLNet model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid(color = 'w')\n",
    "plt.savefig('CNN_accuracy_CNN_relu-test',dpi=200);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce1afb",
   "metadata": {
    "id": "b9ce1afb",
    "outputId": "f4d23514-2783-490d-ae3c-eaa341e4590d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_facecolor(\"#eaeaf2\")\n",
    "plt.plot(history.history['loss'],label=\"train loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"val loss\")\n",
    "plt.title('GLNet model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid(color = 'w')\n",
    "# plt.savefig('CNN_loss_CNN_relu-test',dpi=200);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67cc908",
   "metadata": {
    "id": "b67cc908"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af545b0",
   "metadata": {
    "id": "9af545b0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c139f",
   "metadata": {
    "id": "c00c139f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3b1ab",
   "metadata": {
    "id": "98c3b1ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c32cdc",
   "metadata": {
    "id": "78c32cdc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
